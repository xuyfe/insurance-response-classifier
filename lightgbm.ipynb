{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning Light Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "import optuna\n",
    "from optuna_integration import LightGBMPruningCallback\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = pd.read_csv('scaled_data/xtrain.csv', index_col = 0)\n",
    "xtest = pd.read_csv('scaled_data/xtest.csv', index_col = 0)\n",
    "ytrain = pd.read_csv('scaled_data/ytrain.csv', index_col = 0)\n",
    "ytest = pd.read_csv('scaled_data/ytest.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set LightGBM Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_train = lgb.Dataset(xtrain, label = ytrain, free_raw_data = False)\n",
    "lgb_test = lgb.Dataset(xtest, label = ytest, reference = lgb_train, free_raw_data = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with Core Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_params = {\n",
    "    'boosting_type' : 'gbdt',\n",
    "    'objective' : 'binary',\n",
    "    'learning_rate' : 0.05,\n",
    "    'num_leaves' : 31,\n",
    "    'metric' : 'auc'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gbm(params, train_set, test_set, init_gbm = None, boost_rounds = 100, early_stopping_rounds = 0, metric = 'auc'):\n",
    "\n",
    "    evals_result = {}\n",
    "\n",
    "    gbm = lgb.train(params,\n",
    "                    train_set,\n",
    "                    init_model = init_gbm,\n",
    "                    num_boost_round = boost_rounds,\n",
    "                    # early_stopping_round = early_stopping_rounds,\n",
    "                    valid_sets = [test_set],\n",
    "                    # evals_result = evals_result,\n",
    "                    # verbose_eval = True\n",
    "    )\n",
    "    \n",
    "    y_true = test_set.label\n",
    "\n",
    "    y_pred = gbm.predict(test_set.data)\n",
    "\n",
    "    fpr, tpr, threshold = roc_curve(y_true, y_pred)\n",
    "\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.title('ROC Curve')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    _ = plt.plot(fpr, tpr, 'r')\n",
    "\n",
    "    return gbm, evals_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 49584, number of negative: 353084\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006324 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 738\n",
      "[LightGBM] [Info] Number of data points in the train set: 402668, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.123139 -> initscore=-1.963038\n",
      "[LightGBM] [Info] Start training from score -1.963038\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model, evals = train_gbm(core_params, lgb_train, lgb_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the objective function\n",
    "def objective(trial: optuna.Trial, \n",
    "              train,\n",
    "              test) -> float:\n",
    "    \n",
    "    # define the hyperparameters to tune\n",
    "    hyperparams = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n",
    "        'max_depth': trial.suggest_int('max_depth', 5, 20),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 3e-1),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 1.0),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 1.0),\n",
    "        'bagging_fraction' : trial.suggest_float('bagging_fraction', 0.5, 0.9),\n",
    "        'is_unbalance' : True\n",
    "    }\n",
    "\n",
    "    # pruning\n",
    "    pruning_callback = LightGBMPruningCallback(trial, 'auc')\n",
    "\n",
    "    # train model\n",
    "    lgbm = lgb.train(hyperparams, train, valid_sets = [test], callbacks = [pruning_callback])\n",
    "\n",
    "    y_pred_proba = lgbm.predict(xtest, num_iteration = lgbm.best_iteration)\n",
    "\n",
    "    roc_auc = roc_auc_score(ytest, y_pred_proba)\n",
    "\n",
    "    return float(roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-29 18:29:41,541] A new study created in memory with name: no-name-e0444f79-a2d3-4bc9-b05e-f3c1843e843d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 49584, number of negative: 353084\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006290 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 738\n",
      "[LightGBM] [Info] Number of data points in the train set: 402668, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.123139 -> initscore=-1.963038\n",
      "[LightGBM] [Info] Start training from score -1.963038\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-29 18:30:04,552] Trial 0 finished with value: 0.8764065030006134 and parameters: {'num_leaves': 144, 'max_depth': 8, 'learning_rate': 0.03466391518429615, 'n_estimators': 813, 'min_child_samples': 21, 'colsample_bytree': 0.8031928366234566, 'reg_alpha': 0.44029615310424686, 'reg_lambda': 0.8869632556539264, 'bagging_fraction': 0.7914518542159222}. Best is trial 0 with value: 0.8764065030006134.\n",
      "/Users/owenxuli/Documents/GitHub/insurance-response-classifier/insurance/lib/python3.11/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[LightGBM] [Fatal] Reducing `min_data_in_leaf` with `feature_pre_filter=true` may cause unexpected behaviour for features that were pre-filtered by the larger `min_data_in_leaf`.\n",
      "You need to set `feature_pre_filter=false` to dynamically change the `min_data_in_leaf`.\n",
      "[LightGBM] [Fatal] Reducing `min_data_in_leaf` with `feature_pre_filter=true` may cause unexpected behaviour for features that were pre-filtered by the larger `min_data_in_leaf`.\n",
      "You need to set `feature_pre_filter=false` to dynamically change the `min_data_in_leaf`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.579537420550804, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.579537420550804\n",
      "[LightGBM] [Info] Number of positive: 49584, number of negative: 353084\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003379 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 738\n",
      "[LightGBM] [Info] Number of data points in the train set: 402668, number of used features: 16\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.579537420550804, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.579537420550804\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.123139 -> initscore=-1.963038\n",
      "[LightGBM] [Info] Start training from score -1.963038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-29 18:30:10,769] Trial 1 finished with value: 0.8774680807658308 and parameters: {'num_leaves': 18, 'max_depth': 9, 'learning_rate': 0.1732080006922778, 'n_estimators': 485, 'min_child_samples': 12, 'colsample_bytree': 0.6532730571679977, 'reg_alpha': 0.2824691927675552, 'reg_lambda': 0.8127125917275994, 'bagging_fraction': 0.579537420550804}. Best is trial 1 with value: 0.8774680807658308.\n",
      "/Users/owenxuli/Documents/GitHub/insurance-response-classifier/insurance/lib/python3.11/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.579537420550804, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.579537420550804\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.579537420550804, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.579537420550804\n",
      "[LightGBM] [Info] Number of positive: 49584, number of negative: 353084\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004199 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 738\n",
      "[LightGBM] [Info] Number of data points in the train set: 402668, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.123139 -> initscore=-1.963038\n",
      "[LightGBM] [Info] Start training from score -1.963038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-29 18:30:19,099] Trial 2 finished with value: 0.8757198915907409 and parameters: {'num_leaves': 40, 'max_depth': 10, 'learning_rate': 0.16094370222893722, 'n_estimators': 517, 'min_child_samples': 57, 'colsample_bytree': 0.929779852906037, 'reg_alpha': 0.11785252142972956, 'reg_lambda': 0.8555307419245604, 'bagging_fraction': 0.8280164461260833}. Best is trial 1 with value: 0.8774680807658308.\n",
      "/Users/owenxuli/Documents/GitHub/insurance-response-classifier/insurance/lib/python3.11/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.579537420550804, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.579537420550804\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.579537420550804, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.579537420550804\n",
      "[LightGBM] [Info] Number of positive: 49584, number of negative: 353084\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003053 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 738\n",
      "[LightGBM] [Info] Number of data points in the train set: 402668, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.123139 -> initscore=-1.963038\n",
      "[LightGBM] [Info] Start training from score -1.963038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-29 18:30:25,436] Trial 3 finished with value: 0.8770743433752878 and parameters: {'num_leaves': 9, 'max_depth': 13, 'learning_rate': 0.08614100075986704, 'n_estimators': 604, 'min_child_samples': 92, 'colsample_bytree': 0.8154984807850667, 'reg_alpha': 0.9447605870272505, 'reg_lambda': 0.6587071846838388, 'bagging_fraction': 0.5439482120602344}. Best is trial 1 with value: 0.8774680807658308.\n",
      "/Users/owenxuli/Documents/GitHub/insurance-response-classifier/insurance/lib/python3.11/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.579537420550804, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.579537420550804\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.579537420550804, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.579537420550804\n",
      "[LightGBM] [Info] Number of positive: 49584, number of negative: 353084\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003699 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 738\n",
      "[LightGBM] [Info] Number of data points in the train set: 402668, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.123139 -> initscore=-1.963038\n",
      "[LightGBM] [Info] Start training from score -1.963038\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-29 18:30:44,149] Trial 4 finished with value: 0.8765875589024418 and parameters: {'num_leaves': 120, 'max_depth': 10, 'learning_rate': 0.028457787133937085, 'n_estimators': 650, 'min_child_samples': 40, 'colsample_bytree': 0.9209943523198492, 'reg_alpha': 0.8179871242987509, 'reg_lambda': 0.17136473964298424, 'bagging_fraction': 0.649727215430886}. Best is trial 1 with value: 0.8774680807658308.\n",
      "/Users/owenxuli/Documents/GitHub/insurance-response-classifier/insurance/lib/python3.11/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.579537420550804, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.579537420550804\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.579537420550804, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.579537420550804\n",
      "[LightGBM] [Info] Number of positive: 49584, number of negative: 353084\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003399 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 738\n",
      "[LightGBM] [Info] Number of data points in the train set: 402668, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.123139 -> initscore=-1.963038\n",
      "[LightGBM] [Info] Start training from score -1.963038\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-29 18:31:06,062] Trial 5 finished with value: 0.8744545516883747 and parameters: {'num_leaves': 113, 'max_depth': 18, 'learning_rate': 0.08992144887873323, 'n_estimators': 798, 'min_child_samples': 49, 'colsample_bytree': 0.6484026435509374, 'reg_alpha': 0.18383695752129217, 'reg_lambda': 0.557984659548473, 'bagging_fraction': 0.6899441046531497}. Best is trial 1 with value: 0.8774680807658308.\n",
      "/Users/owenxuli/Documents/GitHub/insurance-response-classifier/insurance/lib/python3.11/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[LightGBM] [Fatal] Reducing `min_data_in_leaf` with `feature_pre_filter=true` may cause unexpected behaviour for features that were pre-filtered by the larger `min_data_in_leaf`.\n",
      "You need to set `feature_pre_filter=false` to dynamically change the `min_data_in_leaf`.\n",
      "[LightGBM] [Fatal] Reducing `min_data_in_leaf` with `feature_pre_filter=true` may cause unexpected behaviour for features that were pre-filtered by the larger `min_data_in_leaf`.\n",
      "You need to set `feature_pre_filter=false` to dynamically change the `min_data_in_leaf`.\n",
      "[I 2024-07-29 18:31:06,161] Trial 6 pruned. Trial was pruned at iteration 0.\n",
      "/Users/owenxuli/Documents/GitHub/insurance-response-classifier/insurance/lib/python3.11/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.579537420550804, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.579537420550804\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.579537420550804, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.579537420550804\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Info] Number of positive: 49584, number of negative: 353084\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003334 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 738\n",
      "[LightGBM] [Info] Number of data points in the train set: 402668, number of used features: 16\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.123139 -> initscore=-1.963038\n",
      "[LightGBM] [Info] Start training from score -1.963038\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Info] Number of positive: 49584, number of negative: 353084\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003619 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 738\n",
      "[LightGBM] [Info] Number of data points in the train set: 402668, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.123139 -> initscore=-1.963038\n",
      "[LightGBM] [Info] Start training from score -1.963038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-29 18:31:11,587] Trial 7 pruned. Trial was pruned at iteration 263.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Info] Number of positive: 49584, number of negative: 353084\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003332 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 738\n",
      "[LightGBM] [Info] Number of data points in the train set: 402668, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.123139 -> initscore=-1.963038\n",
      "[LightGBM] [Info] Start training from score -1.963038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-29 18:31:14,874] Trial 8 pruned. Trial was pruned at iteration 104.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Info] Number of positive: 49584, number of negative: 353084\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003359 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 738\n",
      "[LightGBM] [Info] Number of data points in the train set: 402668, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.123139 -> initscore=-1.963038\n",
      "[LightGBM] [Info] Start training from score -1.963038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-29 18:31:15,602] Trial 9 pruned. Trial was pruned at iteration 33.\n",
      "[I 2024-07-29 18:31:15,645] Trial 10 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-07-29 18:31:15,676] Trial 11 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-07-29 18:31:15,737] Trial 12 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-07-29 18:31:15,801] Trial 13 pruned. Trial was pruned at iteration 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Info] Number of positive: 49584, number of negative: 353084\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003426 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 738\n",
      "[LightGBM] [Info] Number of data points in the train set: 402668, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.123139 -> initscore=-1.963038\n",
      "[LightGBM] [Info] Start training from score -1.963038\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Info] Number of positive: 49584, number of negative: 353084\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003385 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 738\n",
      "[LightGBM] [Info] Number of data points in the train set: 402668, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.123139 -> initscore=-1.963038\n",
      "[LightGBM] [Info] Start training from score -1.963038\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Info] Number of positive: 49584, number of negative: 353084\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003567 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 738\n",
      "[LightGBM] [Info] Number of data points in the train set: 402668, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.123139 -> initscore=-1.963038\n",
      "[LightGBM] [Info] Start training from score -1.963038\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Info] Number of positive: 49584, number of negative: 353084\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003424 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 738\n",
      "[LightGBM] [Info] Number of data points in the train set: 402668, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.123139 -> initscore=-1.963038\n",
      "[LightGBM] [Info] Start training from score -1.963038\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Info] Number of positive: 49584, number of negative: 353084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-29 18:31:15,866] Trial 14 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003363 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 738\n",
      "[LightGBM] [Info] Number of data points in the train set: 402668, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.123139 -> initscore=-1.963038\n",
      "[LightGBM] [Info] Start training from score -1.963038\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Info] Number of positive: 49584, number of negative: 353084\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003564 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 738\n",
      "[LightGBM] [Info] Number of data points in the train set: 402668, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.123139 -> initscore=-1.963038\n",
      "[LightGBM] [Info] Start training from score -1.963038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-29 18:31:20,952] Trial 15 pruned. Trial was pruned at iteration 216.\n",
      "[I 2024-07-29 18:31:21,044] Trial 16 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-07-29 18:31:21,082] Trial 17 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-07-29 18:31:21,111] Trial 18 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-07-29 18:31:21,161] Trial 19 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Info] Number of positive: 49584, number of negative: 353084\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003180 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 738\n",
      "[LightGBM] [Info] Number of data points in the train set: 402668, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.123139 -> initscore=-1.963038\n",
      "[LightGBM] [Info] Start training from score -1.963038\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Info] Number of positive: 49584, number of negative: 353084\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003506 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 738\n",
      "[LightGBM] [Info] Number of data points in the train set: 402668, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.123139 -> initscore=-1.963038\n",
      "[LightGBM] [Info] Start training from score -1.963038\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Info] Number of positive: 49584, number of negative: 353084\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003318 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 738\n",
      "[LightGBM] [Info] Number of data points in the train set: 402668, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.123139 -> initscore=-1.963038\n",
      "[LightGBM] [Info] Start training from score -1.963038\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Info] Number of positive: 49584, number of negative: 353084\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003267 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 738\n",
      "[LightGBM] [Info] Number of data points in the train set: 402668, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.123139 -> initscore=-1.963038\n",
      "[LightGBM] [Info] Start training from score -1.963038\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-29 18:31:21,224] Trial 20 pruned. Trial was pruned at iteration 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Info] Number of positive: 49584, number of negative: 353084\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003337 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 738\n",
      "[LightGBM] [Info] Number of data points in the train set: 402668, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.123139 -> initscore=-1.963038\n",
      "[LightGBM] [Info] Start training from score -1.963038\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Info] Number of positive: 49584, number of negative: 353084\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003215 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 738\n",
      "[LightGBM] [Info] Number of data points in the train set: 402668, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.123139 -> initscore=-1.963038\n",
      "[LightGBM] [Info] Start training from score -1.963038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-29 18:31:21,434] Trial 21 pruned. Trial was pruned at iteration 5.\n",
      "[I 2024-07-29 18:31:21,525] Trial 22 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-07-29 18:31:21,604] Trial 23 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-07-29 18:31:21,641] Trial 24 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Info] Number of positive: 49584, number of negative: 353084\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003619 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 738\n",
      "[LightGBM] [Info] Number of data points in the train set: 402668, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.123139 -> initscore=-1.963038\n",
      "[LightGBM] [Info] Start training from score -1.963038\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Info] Number of positive: 49584, number of negative: 353084\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003617 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 738\n",
      "[LightGBM] [Info] Number of data points in the train set: 402668, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.123139 -> initscore=-1.963038\n",
      "[LightGBM] [Info] Start training from score -1.963038\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Info] Number of positive: 49584, number of negative: 353084\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003710 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 738\n",
      "[LightGBM] [Info] Number of data points in the train set: 402668, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.123139 -> initscore=-1.963038\n",
      "[LightGBM] [Info] Start training from score -1.963038\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Info] Number of positive: 49584, number of negative: 353084\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003793 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 738\n",
      "[LightGBM] [Info] Number of data points in the train set: 402668, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.123139 -> initscore=-1.963038\n",
      "[LightGBM] [Info] Start training from score -1.963038\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-29 18:31:29,767] Trial 25 pruned. Trial was pruned at iteration 263.\n",
      "[I 2024-07-29 18:31:29,811] Trial 26 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-07-29 18:31:29,879] Trial 27 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-07-29 18:31:29,919] Trial 28 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Info] Number of positive: 49584, number of negative: 353084\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003520 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 738\n",
      "[LightGBM] [Info] Number of data points in the train set: 402668, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.123139 -> initscore=-1.963038\n",
      "[LightGBM] [Info] Start training from score -1.963038\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Info] Number of positive: 49584, number of negative: 353084\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003321 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 738\n",
      "[LightGBM] [Info] Number of data points in the train set: 402668, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.123139 -> initscore=-1.963038\n",
      "[LightGBM] [Info] Start training from score -1.963038\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Info] Number of positive: 49584, number of negative: 353084\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003544 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 738\n",
      "[LightGBM] [Info] Number of data points in the train set: 402668, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.123139 -> initscore=-1.963038\n",
      "[LightGBM] [Info] Start training from score -1.963038\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Info] Number of positive: 49584, number of negative: 353084\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003362 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 738\n",
      "[LightGBM] [Info] Number of data points in the train set: 402668, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.123139 -> initscore=-1.963038\n",
      "[LightGBM] [Info] Start training from score -1.963038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-29 18:31:58,944] Trial 29 finished with value: 0.8752042811705775 and parameters: {'num_leaves': 154, 'max_depth': 13, 'learning_rate': 0.03553942486213639, 'n_estimators': 875, 'min_child_samples': 26, 'colsample_bytree': 0.7944676284967704, 'reg_alpha': 0.4195637210311028, 'reg_lambda': 0.3381324538393738, 'bagging_fraction': 0.7242415779452588}. Best is trial 1 with value: 0.8774680807658308.\n",
      "/Users/owenxuli/Documents/GitHub/insurance-response-classifier/insurance/lib/python3.11/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-07-29 18:31:59,046] Trial 30 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-07-29 18:31:59,091] Trial 31 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-07-29 18:31:59,142] Trial 32 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Info] Number of positive: 49584, number of negative: 353084\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003820 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 738\n",
      "[LightGBM] [Info] Number of data points in the train set: 402668, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.123139 -> initscore=-1.963038\n",
      "[LightGBM] [Info] Start training from score -1.963038\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Info] Number of positive: 49584, number of negative: 353084\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003478 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 738\n",
      "[LightGBM] [Info] Number of data points in the train set: 402668, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.123139 -> initscore=-1.963038\n",
      "[LightGBM] [Info] Start training from score -1.963038\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Info] Number of positive: 49584, number of negative: 353084\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003449 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 738\n",
      "[LightGBM] [Info] Number of data points in the train set: 402668, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.123139 -> initscore=-1.963038\n",
      "[LightGBM] [Info] Start training from score -1.963038\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Info] Number of positive: 49584, number of negative: 353084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-29 18:31:59,182] Trial 33 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-07-29 18:31:59,229] Trial 34 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-07-29 18:31:59,268] Trial 35 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003604 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 738\n",
      "[LightGBM] [Info] Number of data points in the train set: 402668, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.123139 -> initscore=-1.963038\n",
      "[LightGBM] [Info] Start training from score -1.963038\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Info] Number of positive: 49584, number of negative: 353084\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003750 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 738\n",
      "[LightGBM] [Info] Number of data points in the train set: 402668, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.123139 -> initscore=-1.963038\n",
      "[LightGBM] [Info] Start training from score -1.963038\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Info] Number of positive: 49584, number of negative: 353084\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003780 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 738\n",
      "[LightGBM] [Info] Number of data points in the train set: 402668, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.123139 -> initscore=-1.963038\n",
      "[LightGBM] [Info] Start training from score -1.963038\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Info] Number of positive: 49584, number of negative: 353084\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003431 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 738\n",
      "[LightGBM] [Info] Number of data points in the train set: 402668, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.123139 -> initscore=-1.963038\n",
      "[LightGBM] [Info] Start training from score -1.963038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-29 18:32:05,555] Trial 36 pruned. Trial was pruned at iteration 184.\n",
      "[I 2024-07-29 18:32:05,622] Trial 37 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-07-29 18:32:05,665] Trial 38 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-07-29 18:32:05,720] Trial 39 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Info] Number of positive: 49584, number of negative: 353084\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003491 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 738\n",
      "[LightGBM] [Info] Number of data points in the train set: 402668, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.123139 -> initscore=-1.963038\n",
      "[LightGBM] [Info] Start training from score -1.963038\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Info] Number of positive: 49584, number of negative: 353084\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003611 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 738\n",
      "[LightGBM] [Info] Number of data points in the train set: 402668, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.123139 -> initscore=-1.963038\n",
      "[LightGBM] [Info] Start training from score -1.963038\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Info] Number of positive: 49584, number of negative: 353084\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003148 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 738\n",
      "[LightGBM] [Info] Number of data points in the train set: 402668, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.123139 -> initscore=-1.963038\n",
      "[LightGBM] [Info] Start training from score -1.963038\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Info] Number of positive: 49584, number of negative: 353084\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004259 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 738\n",
      "[LightGBM] [Info] Number of data points in the train set: 402668, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.123139 -> initscore=-1.963038\n",
      "[LightGBM] [Info] Start training from score -1.963038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-29 18:32:12,233] Trial 40 pruned. Trial was pruned at iteration 166.\n",
      "[I 2024-07-29 18:32:12,295] Trial 41 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-07-29 18:32:12,330] Trial 42 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Info] Number of positive: 49584, number of negative: 353084\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004136 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 738\n",
      "[LightGBM] [Info] Number of data points in the train set: 402668, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.123139 -> initscore=-1.963038\n",
      "[LightGBM] [Info] Start training from score -1.963038\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Info] Number of positive: 49584, number of negative: 353084\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003531 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 738\n",
      "[LightGBM] [Info] Number of data points in the train set: 402668, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.123139 -> initscore=-1.963038\n",
      "[LightGBM] [Info] Start training from score -1.963038\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Info] Number of positive: 49584, number of negative: 353084\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003957 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 738\n",
      "[LightGBM] [Info] Number of data points in the train set: 402668, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.123139 -> initscore=-1.963038\n",
      "[LightGBM] [Info] Start training from score -1.963038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-29 18:32:21,692] Trial 43 finished with value: 0.8738513633179577 and parameters: {'num_leaves': 38, 'max_depth': 12, 'learning_rate': 0.21462805017609016, 'n_estimators': 578, 'min_child_samples': 97, 'colsample_bytree': 0.9264862670666798, 'reg_alpha': 0.06424467437794024, 'reg_lambda': 0.703925922583275, 'bagging_fraction': 0.7740142738376083}. Best is trial 1 with value: 0.8774680807658308.\n",
      "/Users/owenxuli/Documents/GitHub/insurance-response-classifier/insurance/lib/python3.11/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[I 2024-07-29 18:32:21,741] Trial 44 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-07-29 18:32:21,783] Trial 45 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Info] Number of positive: 49584, number of negative: 353084\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003539 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 738\n",
      "[LightGBM] [Info] Number of data points in the train set: 402668, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.123139 -> initscore=-1.963038\n",
      "[LightGBM] [Info] Start training from score -1.963038\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Info] Number of positive: 49584, number of negative: 353084\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003378 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 738\n",
      "[LightGBM] [Info] Number of data points in the train set: 402668, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.123139 -> initscore=-1.963038\n",
      "[LightGBM] [Info] Start training from score -1.963038\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Info] Number of positive: 49584, number of negative: 353084\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003831 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 738\n",
      "[LightGBM] [Info] Number of data points in the train set: 402668, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.123139 -> initscore=-1.963038\n",
      "[LightGBM] [Info] Start training from score -1.963038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-29 18:32:28,860] Trial 46 finished with value: 0.8763746653221762 and parameters: {'num_leaves': 44, 'max_depth': 20, 'learning_rate': 0.1300489519597601, 'n_estimators': 403, 'min_child_samples': 62, 'colsample_bytree': 0.9682490225648378, 'reg_alpha': 0.6380440619854233, 'reg_lambda': 0.9720400845014672, 'bagging_fraction': 0.6868592417114816}. Best is trial 1 with value: 0.8774680807658308.\n",
      "/Users/owenxuli/Documents/GitHub/insurance-response-classifier/insurance/lib/python3.11/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Info] Number of positive: 49584, number of negative: 353084\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003812 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 738\n",
      "[LightGBM] [Info] Number of data points in the train set: 402668, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.123139 -> initscore=-1.963038\n",
      "[LightGBM] [Info] Start training from score -1.963038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-29 18:32:29,202] Trial 47 pruned. Trial was pruned at iteration 16.\n",
      "[I 2024-07-29 18:32:29,265] Trial 48 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-07-29 18:32:29,303] Trial 49 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Info] Number of positive: 49584, number of negative: 353084\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003653 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 738\n",
      "[LightGBM] [Info] Number of data points in the train set: 402668, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.123139 -> initscore=-1.963038\n",
      "[LightGBM] [Info] Start training from score -1.963038\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5470104613730861, subsample=0.8811570078334832 will be ignored. Current value: bagging_fraction=0.5470104613730861\n",
      "[LightGBM] [Info] Number of positive: 49584, number of negative: 353084\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003340 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 738\n",
      "[LightGBM] [Info] Number of data points in the train set: 402668, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.123139 -> initscore=-1.963038\n",
      "[LightGBM] [Info] Start training from score -1.963038\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, \n",
    "                                       train = lgb_train,\n",
    "                                       test = lgb_test),\n",
    "                n_trials = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:  0.8774680807658308\n",
      "Best hyperparameters:  {'num_leaves': 18, 'max_depth': 9, 'learning_rate': 0.1732080006922778, 'n_estimators': 485, 'min_child_samples': 12, 'colsample_bytree': 0.6532730571679977, 'reg_alpha': 0.2824691927675552, 'reg_lambda': 0.8127125917275994, 'bagging_fraction': 0.579537420550804}\n"
     ]
    }
   ],
   "source": [
    "print('Best score: ', study.best_trial.value)\n",
    "print('Best hyperparameters: ', study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = {\n",
    "    'num_leaves': 18, \n",
    "    'max_depth': 9, \n",
    "    'learning_rate': 0.1732080006922778, \n",
    "    'n_estimators': 485, \n",
    "    'min_child_samples': 12, \n",
    "    'colsample_bytree': 0.6532730571679977, \n",
    "    'reg_alpha': 0.2824691927675552, \n",
    "    'reg_lambda': 0.8127125917275994, \n",
    "    'bagging_fraction': 0.579537420550804\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "insurance",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
